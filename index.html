<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Tianle Chen</title>

    <meta name="author" content="Tianle Chen">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Tianle Chen
                </p>
                <p>I'm a first year PhD student in the Image and Video Computing group at Boston Univerisity, where I am fortunate to be advised by Prof. Deepti Ghadiyaram.
                </p>
                Prior to joining BU, I completed my undergraduate study at The Ohio State University.
<!--                <p>-->
<!--                  At Google I've worked on <a href="https://www.google.com/glass/start/">Glass</a>,  <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://blog.google/products/google-ar-vr/introducing-next-generation-jump/">VR</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, and <a href="https://blog.google/products/maps/three-maps-updates-io-2022/">Maps</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>. I've received the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.-->
<!--                </p>-->
                <p style="text-align:center">
                  <a href="tianle@bu.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/Tianle-CV.pdf">CV</a> &nbsp;/&nbsp;
<!--                  <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp;-->
                  <a href="https://scholar.google.com/citations?user=NJUjl7YAAAAJ&hl=zh-CN&oi=ao">Scholar</a> &nbsp;/&nbsp;
<!--                  <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp;/&nbsp;-->
<!--                  <a href="https://github.com/jonbarron/">Github</a>-->
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="Tianle_images/tianle.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="Tianle_images/tianle.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision, especially in image and video processing</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr onmouseout="nuvo_stop()" onmouseover="nuvo_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='nuvo_image'><video  width=100% muted autoplay loop>
          <source src="images/nuvo.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/Colorization.jpg' width=100%>
          <img src='images/Colorization2.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function nuvo_start() {
            document.getElementById('nuvo_image').style.opacity = "1";
          }

          function nuvo_stop() {
            document.getElementById('nuvo_image').style.opacity = "0";
          }
          nuvo_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2310.14592">
          <span class="papertitle">Pre-Training LiDAR-Based 3D Object Detectors Through Colorization</span>
        </a>
        <br>
        <a href="https://tydpan.github.io/">Tai-Yu Pan</a>,
        <a href="https://www.chenyangma.com/">Chenyang Ma</a>,
        <strong>Tianle Chen*</strong>,
        <a href="https://cpphoo.github.io/">Cheng Perng Phoo</a>,
        <a href="https://www.cs.cornell.edu/~katieluo/">Katie Z Luo</a>,
        <a href="https://yurongyou.com/">Yurong You</a>,
        <a href="https://www.mae.cornell.edu/faculty-directory/mark-campbell">Mark Campbell</a>,
        <a href="https://www.cs.cornell.edu/~kilian/">Kilian Q Weinberger</a>,
        <a href="https://sites.google.com/view/wei-lun-harry-chao/home">Bharath Hariharan</a>,
        <a href="https://www.cs.cornell.edu/~bharathh/">Wei-Lun Chao</a>
        <br>
        <em>ICLR</em>, 2024
        <br>
<!--        <a href="https://github.com/cskyl/SAM_WSSS">project page</a>-->
<!--        /-->
<!--        <a href="https://www.youtube.com/watch?v=hmJiOSTDQZI">video</a>-->
        /
        <a href="https://arxiv.org/pdf/2310.14592">arXiv</a>
        <p></p>
<!--        <p>-->
<!--        Neural fields let you recover editable UV mappings for the challenging geometries produced by NeRF-like models.-->
<!--        </p>-->
      </td>



      <tr onmouseout="nuvo_stop()" onmouseover="nuvo_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='nuvo_image'><video  width=100% muted autoplay loop>
          <source src="images/nuvo.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/SAM-WSSS.jpg' width=100%>
          <img src='images/SAM-WSSS2.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function nuvo_start() {
            document.getElementById('nuvo_image').style.opacity = "1";
          }

          function nuvo_stop() {
            document.getElementById('nuvo_image').style.opacity = "0";
          }
          nuvo_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2305.05803">
          <span class="papertitle">Segment anything model (sam) enhanced pseudo labels for weakly supervised semantic segmentation</span>
        </a>
        <br>
        <strong>Tianle Chen*</strong>,
        <a href="https://pratulsrinivasan.github.io/">Zheda Mai*</a>,
        <a href="https://scholar.google.com/citations?user=m7hRl4YAAAAJ&hl=en">Ruiwen Li</a>,
        <a href="https://sites.google.com/view/wei-lun-harry-chao/home">Wei-Lun Chao</a>,
        <br>
        <em>NeruIPS Workshop</em>, 2023
        <br>
        <a href="https://github.com/cskyl/SAM_WSSS">project page</a>
<!--        /-->
<!--        <a href="https://www.youtube.com/watch?v=hmJiOSTDQZI">video</a>-->
        /
        <a href="https://arxiv.org/abs/2305.05803">arXiv</a>
        <p></p>
<!--        <p>-->
<!--        Neural fields let you recover editable UV mappings for the challenging geometries produced by NeRF-like models.-->
<!--        </p>-->
      </td>



      <tr onmouseout="nuvo_stop()" onmouseover="nuvo_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='nuvo_image'><video  width=100% muted autoplay loop>
          <source src="images/nuvo.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/Copy-paste.jpg' width=100%>

        </div>
        <script type="text/javascript">
          function nuvo_start() {
            document.getElementById('nuvo_image').style.opacity = "1";
          }

          function nuvo_stop() {
            document.getElementById('nuvo_image').style.opacity = "0";
          }
          nuvo_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://par.nsf.gov/servlets/purl/10357396">
          <span class="papertitle">Learning with free object segments for long-tailed instance segmentation</span>
        </a>
        <br>
        <a href="https://czhang0528.github.io/">Cheng Zhang</a>,
        <a href="https://tydpan.github.io/">Tai-Yu Pan</a>,
        <strong>Tianle Chen*</strong>,
        <a href="https://jike338.github.io/">Jike Zhong</a>,
        <a href="https://scholar.google.com/citations?user=991LxJoAAAAJ&hl=zh-TW">Wenjin Fu</a>,
        <a href="https://sites.google.com/view/wei-lun-harry-chao/home">Wei-Lun Chao</a>,
        <br>
        <em>ECCV</em>, 2022
        <br>
<!--        <a href="https://github.com/cskyl/SAM_WSSS">project page</a>-->
<!--        /-->
<!--        <a href="https://www.youtube.com/watch?v=hmJiOSTDQZI">video</a>-->
        /
        <a href="https://par.nsf.gov/servlets/purl/10357396">Paper</a>
        <p></p>
<!--        <p>-->
<!--        Neural fields let you recover editable UV mappings for the challenging geometries produced by NeRF-like models.-->
<!--        </p>-->
      </td>



      </tr>
<!--            <tr>-->
<!--              <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--                <img src="images/bd_promo.jpg" alt="blind-date" width="160" height="160">-->
<!--              </td>-->
<!--              <td width="75%" valign="middle">-->
<!--                <a href="https://drive.google.com/file/d/1PQjzKgFcrAesMIDJr-WDlCwuGUxZJZwO/view?usp=sharing">-->
<!--                  <span class="papertitle">Blind Date: Using Proper Motions to Determine the Ages of Historical Images</span>-->
<!--                </a>-->
<!--                <br>-->
<!--                <strong>Jonathan T. Barron</strong>, <a href="http://cosmo.nyu.edu/hogg/">David W. Hogg</a>, <a href="http://www.astro.princeton.edu/~dstn/">Dustin Lang</a>, <a href="http://cs.nyu.edu/~roweis/">Sam Roweis</a>-->
<!--                <br>-->
<!--                <em>The Astronomical Journal</em>, 136, 2008-->
<!--                <p>Using the relative motions of stars we can accurately estimate the date of origin of historical astronomical images.</p>-->
<!--              </td>-->
<!--            </tr>-->


            
            

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <p style="text-align:right;font-size:small;">
                Design and source code from <a href="https://jonbarron.info/">Jon Barron's website</a>
              </p>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
